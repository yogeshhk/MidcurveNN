As we discussed, for easier comprehension of the technical material by the audience here are some enhancements we could make:
1. Compress the introduction of the problem of taking CAD designs to skeletons/medial transforms for CAE models using suitable illustrations, into about 5-7 minutes. 
2. We plan to mention an example of how a 3D design cannot be directly converted to an engineering model (FEM), unless we have information on underlying topology/geometry, that it can be done with rules, but how many rules will one create for different shapes? Hence we are exploring machine learning. 
We have thickness sampling, so we can try to recreate the original points with offsets. Input and output difference can be a quality metric. How CAD design to CAE model can be used to give feedback about design in early stages? In early stages it is OK to have some imperfection in the models and so ML models might suffice. 
3. Why geometry to geometry (=Seq2Seq) models may work for some simple cases, why autoencoders do not apply (we have a new image which is a skeleton) and why we need encoder-decoder approach? Later why Pix to Pix might make sense. When you have data from your PixtoPix work you can include it. 
4. How data with medial representations was created, along with translational, rotational and mirror transforms - and rasterized? How would one create such data for 3D CAD drawings? Voxelization - manual effort. 
5. For later stages of CAD-CAE one may may need more refined models, or need models where one has used some kind of adversarial techniques to find and reduce errors in generation or used some kind of feedback mechanism like reinforcement learning. 
6. For the noise in the output you mentioned that we can use bounding boxes to remove noisy points. We also discussed differencing with the known output expected and feeding that back into the error term. We discussed requiring single pixel image as the skeleton, and rest as noise. 